{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44689c92-89df-4a88-8991-57009c91f7fe",
   "metadata": {},
   "source": [
    "# Exploring Classical Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84913b40-3370-40c7-8e00-b36d03f9f53d",
   "metadata": {},
   "source": [
    "Let's load in any libraries we will use in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b476050-46bf-4386-b90d-c3f49693a6df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sklearn #great machine learning library\n",
    "import pandas as pd #we'll use this to read in our data in a csv file nicely\n",
    "import numpy as np #let's us do lots of math operations\n",
    "import matplotlib.pyplot as plt #for plotting data!\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc942b3a-b7e6-431b-8252-fb4dc17c9bff",
   "metadata": {},
   "source": [
    "# Loading in the Dataset\n",
    "\n",
    "We're going to be using a publicly available dataset -- the 'Maternal Health Risk Data', available from https://www.kaggle.com/datasets/csafrit2/maternal-health-risk-data\n",
    "\n",
    "From the dataset website: \"Data has been collected from different hospitals, community clinics, maternal health cares through the IoT based risk monitoring system.\n",
    "\n",
    "* Age: Age in years when a woman is pregnant.\n",
    "* SystolicBP: Upper value of Blood Pressure in mmHg, another significant attribute during pregnancy.\n",
    "* DiastolicBP: Lower value of Blood Pressure in mmHg, another significant attribute during pregnancy.\n",
    "* BS: Blood glucose levels is in terms of a molar concentration, mmol/L.\n",
    "* HeartRate: A normal resting heart rate in beats per minute.\n",
    "* Risk Level: Predicted Risk Intensity Level during pregnancy considering the previous attributes.\"\n",
    "\n",
    "We're going to see if we can predict the Risk Level of a patient -- low risk, medium risk, or high risk -- based on the other variables provided.\n",
    "\n",
    "Below, I'm going to load in the dataset and do some initial processing. There's nothing for you to change here, but I'll leave comments in case you're interested on what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362b991a-873d-4cd5-a971-244c6318c640",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_data = pd.read_csv('Maternal Health Risk Data Set.csv')   #read the file into a pandas data frame\n",
    "\n",
    "print(all_data.info())   #we can call this command to get some stats on the dataset, including the features we have, the number of data points for each category, and the data type for each category\n",
    "\n",
    "#converting both to numpy, as these will be easier to work with following on from here\n",
    "input_features = ['Age', 'SystolicBP', 'DiastolicBP', 'BS', 'BodyTemp', 'HeartRate']\n",
    "input_data = all_data[input_features].to_numpy()\n",
    "\n",
    "gt_output = all_data['RiskLevel'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e3125a-f5fc-460e-8cea-fa050f27d8d5",
   "metadata": {},
   "source": [
    "Above, we can see that there are 1014 data points for a variety of features. \n",
    "\n",
    "We're interested in using features 0-5 to help us predict which risk level the patient has -- 'low risk', 'medium risk', or 'high risk'.\n",
    "\n",
    "### Question: What ML Task are we performing here?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfefcad2-aba2-44b6-bb81-5bc3283c0a71",
   "metadata": {},
   "source": [
    "# Inspect the Data\n",
    "\n",
    "Let's look at some of the input_data and gt_output to get a feel for it's current format and what we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ddae4e-1aa2-4178-bc16-c8f2f9fc4a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f15d8afb-d2bd-4792-bd79-7a42776b89ea",
   "metadata": {},
   "source": [
    "# Normalise the data\n",
    "\n",
    "The different features in input_data have very different scales - find the minimum and maximum values, and then apply min-max scaling to normalise the data to be between 0 and 1.\n",
    "\n",
    "$$ x_{norm} = {x-x_{min}\\over x_{max}-x_{min}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f741c41f-f823-4633-b3cd-ad8c0f9b0089",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "030bb905-7a20-4275-8c69-0b2582e68d40",
   "metadata": {},
   "source": [
    "# Training, Validation and Test Subsets \n",
    "\n",
    "We have 1014 data points, and we are going to split this data in the following way:\n",
    "- we have 50% for the training subset, and 25% each for the validation and test subsets\n",
    "- we want to do so randomly with a random state of 0\n",
    "- we want to create a stratified split\n",
    "\n",
    "Use the same approach that we used in Week 1 -- the sklearn train_test_split function -- https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc7e98b-597f-4934-a094-db344be0fda0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38af4ae3-4329-4038-bf14-d60ba8139936",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total Dataset shape:')\n",
    "print(f'    Input shape: {input_data.shape}   GT shape: {gt_output.shape}')\n",
    "print('Train Subset shape:')\n",
    "print(f'    Input shape: {input_train.shape}   GT shape: {gt_train.shape}')\n",
    "print('Validation Subset shape:')\n",
    "print(f'    Input shape: {input_val.shape}   GT shape: {gt_val.shape}')\n",
    "print('Test Subset shape:')\n",
    "print(f'    Input shape: {input_test.shape}   GT shape: {gt_test.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68b8eb0-c9b7-4d16-b9b3-99b3764d6343",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([gt_train, gt_val, gt_test]) #can add density = True to see normalised densities\n",
    "plt.xlabel('GT Classification')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5a662c-ae6b-4d23-90d9-004069151af5",
   "metadata": {},
   "source": [
    "# Model 1: Implementing a K Nearest Neighbour Model\n",
    "\n",
    "## K=1 Nearest Neighbour\n",
    "Let's use the sklearn KNeighborsClassifier -- this uses a K Nearest Neighbour approach to classification, and start with a value of K = 1 to create a simple nearest neighbour classifier.\n",
    "You can read from the documentation here: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845d40ec-1b66-4d0c-95a5-8f18a85925e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab77443b-3014-464a-8910-7d4e73f6cdbc",
   "metadata": {},
   "source": [
    "## Use the validation dataset to find hyperparameter K\n",
    "\n",
    "Let's use the validation dataset to find the best value of K! You can adapt the code above to search through a range of K values, store the validation accuracy, and then store the best value of K in a variable called *K_best*.\n",
    "\n",
    "It's also a good idea to plot the results you get, using something like plt.plot() -- see here: https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.plot.html\n",
    "\n",
    "Sometimes, you'll get similar performance with a high value of K and a low value of K -- remember: the lower value is usually the better choice in this case (see Occam's razor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f197a5-e52e-4c54-ae03-7c312de79475",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "025e3d05-3edc-4eb6-8296-6786c6e3a269",
   "metadata": {},
   "source": [
    "## Find KNN Performance on the Test Data \n",
    "\n",
    "Now that we've used our validation dataset to find the best value of K, let's use this value of K to create a model, and then test it on the test data to see the final 'real-world' performance.\n",
    "\n",
    "It'll be very similar to the approach from above -- you're still using a KNeighborsClassifier and fitting it to the training data subset. This time, use the K_best variable and test on the test data to find the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2116b8-461a-4679-88e7-1c0a3194e7a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0d96787-2920-4982-9e57-4470c5fc3b98",
   "metadata": {},
   "source": [
    "## Visualise performance with a confusion matrix\n",
    "\n",
    "Create a Confusion Matrix based on the performance of the KNN model on the test dataset.\n",
    "\n",
    "Looking at the Confusion Matrix, reflect on the following questions:\n",
    "1. Is performance consistent across the classes, or is there a clear discrepancy for some classes? If there is, why do you think this might be?\n",
    "2. Given the potential use of this ML model, are some types of errors worse or more dangerous than others? How does the KNN model perform for these types of errors? (e.g. if a patient is medium risk, is it better or worse for them to be misclassified as low risk or high risk?)\n",
    "\n",
    "Sklearn has a useful function -- ConfusionMatrixDisplay.from_predictions() -- that creates a confusion matrix if given an array of predicted labels and an array of true labels. Read the documentation here: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html#sklearn.metrics.ConfusionMatrixDisplay.from_predictions\n",
    "\n",
    "Note: you may want to use the normalize argument in the above function to allow easy interpretation in the presence of class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e609ecd0-1579-4e3a-94b7-18b27a2a2f3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77209788-bcb1-4f40-9722-722cc806ea0c",
   "metadata": {},
   "source": [
    "# Model 2: Implementing a Decision Tree\n",
    "\n",
    "## Create a decision tree\n",
    "In the cell below, implement the sklearn DecisionTreeClassifier using a random_state of 0. \n",
    "Read the sklearn documentation on DecisionTreeClassifier to see how to implement -- https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "\n",
    "You will follow a similar process to the KNN model: creating the model, fitting it to the training data, and finding the accuracy on the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61506aa-194a-4749-b47e-ed0462e793cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b0ee8f-be6b-45ae-98ba-85a83f50b773",
   "metadata": {},
   "source": [
    "## Use the validation dataset to select the best maximum depth for the tree\n",
    "\n",
    "In the lecture, we explored how overfitting in decision trees can be mitigated by 'pruning' the decision tree. One technique is 'pre-pruning', where we prevent overfitting while creating the decision tree. You can do this by specifying the maximum depth the tree can reach.\n",
    "\n",
    "Test over a range of maximum depths to find the best performance on the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe065448-34e2-4260-bf2b-f6cbea7ca17a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "680540d6-732a-45c1-b3fd-73c6de255158",
   "metadata": {},
   "source": [
    "## (For your interest) Visualise the Decision Tree!\n",
    "\n",
    "You can use the code below to visualise the decision tree. \n",
    "\n",
    "Things to note: \n",
    "* Normally the features would not be normalised, making this more interpretable.\n",
    "* It's still a very busy decision tree! This is not necessarily from overfitting, it also indicates a complex decision boundary between input data and output predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de94e45-fc92-4f5c-bb36-14936add1cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "dt_model = DecisionTreeClassifier(random_state=0, max_depth = best_depth)\n",
    "dt_model.fit(input_train, gt_train)\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "tree.plot_tree(dt_model, feature_names = input_features, class_names = ['low risk', 'mid risk', 'high risk'], fontsize = 6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff479d9-471e-47de-acd0-4d83778bc638",
   "metadata": {},
   "source": [
    "## Find the performance on the test dataset with your selected best maximum depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98d0c5e-7fba-419f-b647-c9c156617bca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d11e7650-e0fe-4623-81dd-4d6cdba7f4e4",
   "metadata": {},
   "source": [
    "## Visualise performance with a confusion matrix\n",
    "\n",
    "Use the same approach as earlier.\n",
    "\n",
    "How does performance compare with the KNN classifier? Does it have a similar distribution of errors, or different? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a006ffe8-1bad-4d48-83c4-5f776c612b1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27b3b67f-1608-49e9-b96a-af001763115f",
   "metadata": {},
   "source": [
    "# Make a Recommendation!\n",
    "Q: The dataset has been collected from different hospitals, community clinics, and maternal health cares through the IoT based risk monitoring system. You have tested the K Nearest Neighbour classifier and the Random Forest classifier for Queensland Health -- your client. The client is planning to deploy a ML model that allows for automatic classification of pregnancy risk level in community clinics that have less Obstetrics* expertise available or do not have enough staff to cope with current demand. The client is asking for your opinion on the following:\n",
    "\n",
    "(i) Which classifier should we use, and why?\n",
    "\n",
    "(ii) Are there any characteristics of performance that we should be aware of (i.e. differences in performance based on risk level, etc.)?\n",
    "\n",
    "*Obstetrics is the field of study concentrated on pregnancy, childbirth and the postpartum period. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4992b8b3-4fcf-4254-87de-b6a0aa3fe494",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
